# **CNN**

The full name of **CNN** is **convolutional neural network**

## Structure of CNN

**CNN** is divided into three layers, including **Convolutional Layer**，**Pooling Layer**,**Fully Connected Layer** and Other Layer,such as **Activation  layers**，**Input layer**.

### Arrangement law of layers

The most common form of **CNN** is to put some **convolution layers** and **Activation layers** together, followed by the **Pooling layer**, and then repeat this until the data is spatially reduced to a sufficiently small size.  The final full **connection layer** gets output, such as classification score. In other words, the most common **CNN** structure is as follows:

![arrangement_law_layers](/home/sunjianwen/DeepLearning/Picture_resources/arrangement_law_layers.png)

### Size selection of convolution layer

The combination of several small filter **convolution layers** is better than one large filter **convolution layer**

First, the structure in which multiple **convolution layers** alternate with nonlinear **Activation layers** can extract deeper and better features than the structure of a single **convolution layer**,Secondly,The combination of several small **filters** uses fewer parameters than a large **filter**,However, the former also has a disadvantages. During the **Backpropagation**, the **convolution layer** in the middle may occupy more memory.

#### #Backpropagation

When the output data is quite different from the goals and standards we set, **Backpropagation** is required. By using **Backpropagation**, calculating the **partial derivatives** of the objective function to the weights of each **neuron** are obtained layer by layer to form the gradient of the objective function to the weight vector. this is in order to provide the basis for the optimization of the weights After the weights are optimized, the **Forwardpropagation** is switched

## Convolutional Layer

For **extracting features**,use a **filter** to move from the upper left corner of the matrix and record the results of multiplying the **filter** with the corresponding area of the matrix to get a new matrix,the filter width and height are small, and the depth is consistent with the input data 

![convolution_layer](/home/sunjianwen/DeepLearning/Picture_resources/convolution_layer.png)

### Convolution

The **convolution** can convert the data to the frequency channel

### Receptive Field

The definition of receptive field is the area size on the input picture correspond to  the pixel points on the feature map output by each layer of convolutional neural network  

### Convolution kernel

**convolution kernel** also known as **filter**, has a set of neurons with fixed weights, usually n x m two-dimensional matrix

### Convolutional Layer

Multiple **filters** are superimposed to form a convolution layer

**Gif demo**：

![Convolution_calculation.gif](/home/sunjianwen/DeepLearning/Picture_resources/Convolution_calculation.gif)

In the input 7x7x3 in the figure, 7 x 7 represents the height and width of the image, and 3 represents the three color channels of R, G ,B. And there is a filling 0 around the image; There are two **convolution kernels** filter W0 and filter W1, and each filter has a set of W weights corresponding to each channel; After a **filter** move to a position, calculate the **convolution** sum of three channels  and add **bias** to obtain the final result of the filter at that position; The output of each filter is the summary of each channel; The number of outputs is the same as the number of filters. So two different outputs can be obtained on the demo's right.

### The parameter of Filter 

The **depth** determines the output depth and also represents the number of filters,The **stride** determines how many steps to slide to the edge, The **zero-padding** determines add several circles of 0 on the peripheral edge .

![parameter_of_filter](/home/sunjianwen/DeepLearning/Picture_resources/parameter_of_filter.png)

### Weight sharing

The **filter** slides, causing the input to change, but the weight of the  filter W0 is fixed, which is the so-called **weight sharing mechanism** in CNN

![weight_sharing1](/home/sunjianwen/DeepLearning/Picture_resources/weight_sharing1.png)

![weight_sharing2](/home/sunjianwen/DeepLearning/Picture_resources/weight_sharing2.png)



### Feature map

The input data and the **Convolutional kernel** perform Convolution operation, and the result is the Feature graph

There are several convolution kernels between layers. Each feature map of the upper layer is convoluted with each convolution kernel to generate a feature map of the next layer

Usually, the number of feature maps will be generated by the number of convolution kernel filters, that is, the number of layers of in the figure below, and also the depth of this layer. The deeper the network, the more the number of feature maps of this layer will be. With the deepening of the network, the length and width of the feature maps will be reduced, and the features extracted from each feature map of this convolution layer will be more representative. Therefore, the number of feature maps of the next convolution layer needs to be increased, that is, more convolution cores are used for convolution operation, so that the features of the previous layer can be fully extracted.

![feature_map](/home/sunjianwen/DeepLearning/Picture_resources/feature_map.png)

## Pooling Layer

The **pooling layer** is usually periodically inserted between successive **convolution layers**. Its function is to gradually reduce the spatial size of the data. In this way, the number of parameters in the network can be reduced, the consumption of computing resources can be reduced, and the overfitting can be effectively controlled.

The **pooling layer** has a dual purpose: to reduce the sensitivity of the **convolution layer** to the position and to the spatial **downsampling** representation.

### Functions of pooling layer

#### Feature invariance

The **pooling** operation is to resize the image,The information removed during **image compression** is only some **irrelevant** information, while the information left is the **feature with scale invariance**, which is the most representative feature of the image.

#### Feature dimensionality reduction

An image contains a lot of information and features, but some of the information is not useful or repetitive for us. We can remove such **redundant information** and extract the most important features. This is also a major role of **pooling operation**

#### Prevent overfitting

### Maximum and Average Pooling layers

The **Pooling layer** operator consists of a fixed-shape window that slides over all areas according to the input step size, calculating an output for each location traversed by a a **pooled window**. The pool operator is deterministic, and we usually calculate the **maximum** or **average** of all elements in the **pooled window**. These operations are called **maximum pooling** and **average pooling**.

Practice shows that the effect of **maximum pooling** is better than that of **average pooling**



## Fully Connected Layer

**Fully connected layers** play the role of "Classifier" in the whole **CNN**. Each of the **fully connected layers** is a tiled structure composed of many neurons. And mapping distributed **feature representation** to **sample tag space** In order to reduce the influence of feature location on classification

![full_connected_layer](/home/sunjianwen/DeepLearning/Picture_resources/full_connected_layer.png)

Most of **fully connected layer** are above two layers,because Similar to **Taylor's formula**, here a neuron in one layer of the **fully connected layer** can be regarded as a **polynomial**, and many neurons are used to fit the **data distribution**,However, it is sometimes impossible to solve **nonlinear** problems with only one **fully connected layer**,If there are two or more **fully connected layers**, the **nonlinear** problem can be solved well

The function of **full connection layer** is to extract features,The role of the **full connection  layer** is classification

## Other Layer

There are other layers, similar to the **activation layer**, **the input layer**.

###  **Activation layer**

The **activation layer** is mainly composed of **activation function**.

The **convolution layer** output is mapped **nonlinearly**.

### Activation function

The main function of the **activation function** is to provide the **nonlinear** modeling capability of the network.

If the input changes very little, resulting in a completely different output structure, which we do not want to see, in order to simulate a more subtle change, the input and output values are not only 0 to 1, but can be any number between 0 and 1

We assign a weight to each pixel point by using the **convolution** in the **neural network**. This operation is **linear**. We need to introduce the **non-linear** factor. The **activation function** is used to add the **non-linear** factor.

#### The role of the activation function

Assuming that a **neural network** contains only **linear** **convolution** and **full connection operations**, the network can only express linear mapping, and even if the depth of the network is increased, it is still **linear mapping**, which is difficult to effectively model the nonlinear distributed data in the actual environment. After the activation function is added, the **deep neural network** has the layered **nonlinear mapping** learning ability. Therefore, the **activation function** is an indispensable part of the **deep neural network**. 

#### Properties of the activation function

Differentiability: this property is necessary when the optimization method is based on gradient.

Monotonicity: when the activation function is monotone, the single-layer network can be guaranteed to be convex.

Range of output value: when the output of the activation function is limited, the gradient based optimization method will be more stable, because the representation of features is more significantly affected by the limited weight;

When the output of the activation function is infinite, the training of the model will be more efficient. However, in this case, a smaller learning rate is generally required

#### Several activation functions

##### SIGMOID function

![sigmoid](/home/sunjianwen/DeepLearning/Picture_resources/sigmoid.png)

##### #Sigmoid has **soft saturation**

Saturation can be divided into soft saturation and hard saturation. Where, soft saturation means that the derivative of the function approaches 0, and hard saturation means that the derivative of the function is equal to 0

##### Tanh function

![tanh](/home/sunjianwen/DeepLearning/Picture_resources/tanh.png)

Its convergence speed is faster than **sigmoid**, the number of iterations is reduced, and it also has **soft saturation**, thus causing the **gradient** to disappear

- Sigmoid & Tanh:

![tanhVSsigmoid](/home/sunjianwen/DeepLearning/Picture_resources/tanhVSsigmoid.png)

##### Relu function

![relu](/home/sunjianwen/DeepLearning/Picture_resources/relu.png)

**Hard saturation** occurs when x<0 and there is no saturation problem when x>0. Therefore, **ReLU** can maintain the **gradient** at x>0 without decaying, thereby alleviating the problem of **gradient** disappearance. However, as the training progresses, some inputs fall into the **hard saturated** region, which prevents the corresponding weights from being updated, a phenomenon known as **neuron death**.

Similar to **sigmoid**, the output mean of **ReLU** is greater than 0. The convergence of the network is affected by both offset and neuronal death.

##### Leaky-ReLU and P-ReLU functions

For hard saturation in the ReLU function, Leaky-ReLU and P-ReLU appear, which are similar in form, but different in Leaky-ReLU. α Is a constant,but in P-ReLU, a can also be learned as a parameter

![Leaky-ReLUandP-ReLU](/home/sunjianwen/DeepLearning/Picture_resources/Leaky-ReLUandP-ReLU.png)

##### ELU function

This function combines sigmoid and ReLU, with soft saturation on the left and unsaturation on the right. The linear part on the right allows the ELU function to alleviate the loss of gradients, while the soft saturation on the left makes the ELU function more robust to input variations or noise. Moreover, the output mean of the ELU function is close to zero, so the convergence rate is faster.

![ELU](/home/sunjianwen/DeepLearning/Picture_resources/ELU.png)



### Input layer

This layer mainly preprocesses the original image data, including **De-mean**, **Normalization**,PCA/Whitening

#### De-mean 

Centers each dimension of the input data to zero, as shown in the following figure, with the goal of pulling the center of the sample back to the origin of the coordinate system.

#### Normalization: 

Range normalization to the same extent.

![De-meanandNormalization](/home/sunjianwen/DeepLearning/Picture_resources/De-meanandNormalization.png)

#### PCA 

use **PCA** to **reduce dimension**; 

#### Whitening

**Whitening** is the **normalization** of the amplitude on each characteristic axis of the data

![PCAandWhitening](/home/sunjianwen/DeepLearning/Picture_resources/PCAandWhitening.png)

## Computational considerations

When building a **CNN** structure, the biggest bottleneck is memory, so how to reduce memory consumption is a problem worth considering. Three memory sources:

- From **Intermediate Data Volume** Size: Each layer in the **CNN** has the original values of the **active data volume** and the gradient of the loss function to them . Typically, most of the **activation data** is in the front layer of the network. This data needs to be stored in memory during training, since it is also used for **Backpropagation**
- From the parameter size: the number of parameters for the entire network, their gradient values in **Backpropagation**, and each step of the calculation cache when optimized using **momentum**, **Adagrad**, or **RMSProp**. Therefore, memory for storing parameter vectors usually needs to be multiplied by 3 or more on the basis of the capacity of the parameter vectors.
- **CNN** implementation also has a variety of scattered memory usage, such as batches of **training data**, **expanded data**, and so on.

## Case Learning

- **LeNet**
- **AlexNet**
- **ZF Net**
- **GoogLeNet**
- **Inception-v4**
- **VGGNet**
- **ResNet**

## Summary

**CNN** is essentially an input-output mapping. It can learn a large number of mapping relationships between input and output without any exact **mathematical expression** between input and output. As long as the **CNN** is trained in a known pattern, the network has the ability to map between input and output pairs.

